{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7530ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.transforms import v2 as transforms_v2\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import decode_image\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import time\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6022d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e10d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and local path for saving weights\n",
    "model_resnet_18 = models.resnet18()\n",
    "weights_path = \"./output/resnet18_weights.pth\"\n",
    "\n",
    "# Check if the file exists locally\n",
    "if os.path.exists(weights_path):\n",
    "    print(\"âœ… Loading existing ResNet-18 weights...\")\n",
    "    state_dict = torch.load(weights_path, map_location=\"cpu\")\n",
    "    model_resnet_18.load_state_dict(state_dict)\n",
    "else:\n",
    "    print(\"â¬‡ï¸  Downloading ResNet-18 weights...\")\n",
    "    model_resnet_18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)  # Downloads pretrained weights\n",
    "    torch.save(model_resnet_18.state_dict(), weights_path)\n",
    "    print(\"ðŸ’¾ Weights saved locally at:\", weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26aba8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a562bbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dataset on  /Users/leonardomassaro/Desktop/DatasetOxford_prof/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_paths = [\"/Users/leonardomassaro/Desktop/DatasetOxford_prof/\", \"/scratch.hpc/leomass/ipcv-assignment-2/dataset/\", \"/scratch.hpc/leonardo.massaro2/ipcv-assignment-2/dataset/\"]\n",
    "correct_path = None\n",
    "\n",
    "for path in dataset_paths:\n",
    "    if os.path.exists(path) and os.path.isdir(path):\n",
    "        print(\"Detected dataset on \", path)\n",
    "        correct_path = path\n",
    "if not correct_path:\n",
    "    raise Exception(\"No dataset found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b1410c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OxfordPetDataset(Dataset):\n",
    "    def __init__(self, path, file_name, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.filename = file_name\n",
    "        self.root = Path(path)\n",
    "        self.transform = transform\n",
    "        self.names, self.labels = self._get_names_and_labels()\n",
    "        tot_size_bytes = 0\n",
    "        n_images = 0\n",
    "        loaded_data = []\n",
    "        idx = 0\n",
    "        while idx < len(self.names):\n",
    "            name = self.names[idx]\n",
    "            img_tensor = self.get_img_from_filesystem(name)\n",
    "            tot_size_bytes += img_tensor.numel() * img_tensor.element_size()\n",
    "            n_images += 1\n",
    "            loaded_data.append(img_tensor)\n",
    "            idx += 1\n",
    "        print(\"tot size\", tot_size_bytes, \"bytes, for\", n_images, \"images\")\n",
    "        self.data_tensor = torch.stack(loaded_data).to(device=device)\n",
    "        self.labels = torch.Tensor(self.labels).type(torch.LongTensor).to(device=device)\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        img = self.data_tensor[idx]\n",
    "        img = self.transform(img).to(device)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "    def get_img_from_filesystem(self, name) -> Tensor:\n",
    "        img_path = self.root / \"images\" / f\"{name}.jpg\"\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = transforms_v2.Resize((256,256))(img)\n",
    "        img = transforms_v2.ToTensor()(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def get_num_classes(self) -> int:\n",
    "        return max(self.labels) + 1\n",
    "\n",
    "    def _get_names_and_labels(self) -> Tuple[List[str], List[int]]:\n",
    "        names = []\n",
    "        labels = []\n",
    "\n",
    "        with open(self.root / \"annotations\" / self.filename) as f:\n",
    "            for line in f:\n",
    "                if(line[0] == \"#\"):\n",
    "                    continue\n",
    "                name, label = line.replace(\"\\n\", \"\").split(\" \")\n",
    "                names.append(name),\n",
    "                labels.append(int(label) - 1)\n",
    "\n",
    "        return names, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "717893bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scheduler, lr_data):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        lr_data.append(optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3a6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    accuracy = 100*correct\n",
    "    return accuracy, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f434df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(test_loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs, labels\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # --- Accuracy ---\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # --- Confusion Matrix ---\n",
    "    num_classes = outputs.shape[1]\n",
    "    conf_matrix = torch.zeros(num_classes, num_classes, dtype=torch.int64)\n",
    "    for t, p in zip(all_labels, all_preds):\n",
    "        conf_matrix[t, p] += 1\n",
    "\n",
    "    # --- Precision, Recall, F1 ---\n",
    "    tp = conf_matrix.diag()\n",
    "    fp = conf_matrix.sum(dim=0) - tp\n",
    "    fn = conf_matrix.sum(dim=1) - tp\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-12)\n",
    "    recall = tp / (tp + fn + 1e-12)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-12)\n",
    "\n",
    "    # Weighted (by class support)\n",
    "    support = conf_matrix.sum(dim=1)\n",
    "    weighted_precision = (precision * support).sum() / support.sum()\n",
    "    weighted_recall = (recall * support).sum() / support.sum()\n",
    "    weighted_f1 = (f1 * support).sum() / support.sum()\n",
    "\n",
    "    return {\n",
    "        \"test_accuracy\": accuracy,\n",
    "        \"test_precision\": weighted_precision.item(),\n",
    "        \"test_recall\": weighted_recall.item(),\n",
    "        \"test_f1\": weighted_f1.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b01ede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(parameters):\n",
    "\n",
    "    BATCH_SIZE = parameters[\"batch_size\"]\n",
    "    N_DENS_BLKS = parameters[\"n_dense_blocks\"]\n",
    "    N_CONVS_EACH_BLCK = parameters[\"n_conv_each_block\"]\n",
    "    GRWTH_RATE = parameters[\"growth_rate\"]\n",
    "    DROPOUT = parameters[\"dropout\"]\n",
    "    BASE_LR = parameters[\"base_learning_rate\"]\n",
    "    WARMUP_ITERS = parameters[\"warmup_iter\"]\n",
    "    MAIN_SCH_KICK = parameters[\"main_sched_epochs_kick_in\"]\n",
    "    EPOCHS = parameters[\"n_epochs\"]\n",
    "\n",
    "    MEAN = [0.485, 0.456, 0.406]\n",
    "    STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "    training_transform_stack = transforms_v2.Compose([\n",
    "        transforms_v2.RandomResizedCrop(size=(224, 224)),\n",
    "        transforms_v2.RandomHorizontalFlip(p=0.5),\n",
    "        transforms_v2.ColorJitter(                               \n",
    "            brightness=0.5, \n",
    "            contrast=0.5, \n",
    "            saturation=0.5, \n",
    "            hue=0.1\n",
    "        ),\n",
    "        transforms_v2.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1.0)), \n",
    "        transforms_v2.ToDtype(torch.float32, scale=True),\n",
    "        transforms_v2.Normalize(mean=MEAN,\n",
    "                    std=STD),\n",
    "    ])\n",
    "\n",
    "    validation_transform_stack = transforms_v2.Compose([\n",
    "        transforms_v2.Resize(256),\n",
    "        transforms_v2.CenterCrop(224),\n",
    "        transforms_v2.Normalize(MEAN, STD)\n",
    "    ])\n",
    "\n",
    "    train_dataset = OxfordPetDataset(correct_path, file_name=\"train.txt\" , transform=training_transform_stack)\n",
    "    validation_dataset = OxfordPetDataset(correct_path, file_name=\"val.txt\" , transform=validation_transform_stack)\n",
    "    test_dataset = OxfordPetDataset(correct_path, file_name=\"test.txt\" , transform=validation_transform_stack)\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # -----------\n",
    "    num_features = model_resnet_18.fc.in_features\n",
    "    model_resnet_18.fc = nn.Linear(num_features, 37)  \n",
    "\n",
    "    # Freeze everything\n",
    "    for param in model_resnet_18.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze only the head\n",
    "    for param in model_resnet_18.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # -----------\n",
    "\n",
    "    model = model_resnet_18.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=BASE_LR)\n",
    "\n",
    "    warmup_scheduler = lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1., total_iters=WARMUP_ITERS)\n",
    "    main_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=15)\n",
    "\n",
    "    batch_lrs = []           # record learning rate per batch\n",
    "    epoch_end_indices = []   # store index (batch count) at the end of each epoch\n",
    "\n",
    "    net_performance_data = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_accuracy\": []\n",
    "    }\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    for t in range(EPOCHS):\n",
    "        net_performance_data[\"train_loss\"].append( train(train_dataloader, model, loss_fn, optimizer, warmup_scheduler, batch_lrs) )\n",
    "        val_accuracy, val_loss = test(validation_dataloader, model, loss_fn)\n",
    "        if t > MAIN_SCH_KICK: main_scheduler.step(val_accuracy)\n",
    "        net_performance_data[\"val_loss\"].append( val_loss )\n",
    "        net_performance_data[\"val_accuracy\"].append( val_accuracy )\n",
    "        epoch_end_indices.append(len(batch_lrs))\n",
    "\n",
    "    t2 = time.time()\n",
    "    elapsed_time = t2-t1\n",
    "\n",
    "    print(\"Done in \", elapsed_time, \" sec\")\n",
    "\n",
    "    print(\"Best accuracy \", np.max(net_performance_data[\"val_accuracy\"]))\n",
    "\n",
    "    net_performance_data_df = pd.DataFrame(data=net_performance_data)\n",
    "    \n",
    "    #add all experiment parameters to the result dataframe\n",
    "    for key in parameters:\n",
    "        if isinstance(parameters[key], list):\n",
    "            for i, el in enumerate(parameters[key]):\n",
    "                net_performance_data_df[key + \"_\"+ str(i)] = el\n",
    "        else:\n",
    "            net_performance_data_df[key] = parameters[key]\n",
    "    \n",
    "    # add elapsed time\n",
    "    net_performance_data_df[\"elapsed_time_sec\"] = elapsed_time\n",
    "\n",
    "    # create a column for epochs steps indexes\n",
    "    net_performance_data_df = net_performance_data_df.reset_index().rename(columns={\"index\":\"epoch\"})\n",
    "\n",
    "    # add final evaluation stats\n",
    "    eval_performaces = evaluate_model(test_dataloader, model)\n",
    "    for metric in eval_performaces:\n",
    "        net_performance_data_df[metric] = eval_performaces[metric]\n",
    "\n",
    "    return net_performance_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae0adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_base = [\n",
    "{\n",
    "    \"experiment_name\": \"early_lr_sched_change\",\n",
    "    \"batch_size\" : 64,\n",
    "    \"n_dense_blocks\": 3,\n",
    "    \"n_conv_each_block\": [6,16,14],\n",
    "    \"growth_rate\": 24,\n",
    "    \"dropout\": 0.2,\n",
    "    \"base_learning_rate\": 0.001,\n",
    "    \"warmup_iter\": 3500,\n",
    "    \"main_sched_epochs_kick_in\": 40,\n",
    "    \"n_epochs\": 17\n",
    "},\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf7f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_results = []\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "### Actual run of the experiments\n",
    "for par in parameters_base:\n",
    "    total_results.append(run_experiment(par))\n",
    "    # update partial results after each experiment\n",
    "    df_combined = pd.concat(total_results, ignore_index=True)\n",
    "    df_combined[\"val_accuracy\"].plot()\n",
    "    plt.show()\n",
    "    #df_combined.to_csv(f\"./output/results_{timestamp}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
