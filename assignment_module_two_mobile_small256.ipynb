{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d41535fd",
      "metadata": {
        "id": "d41535fd"
      },
      "source": [
        "# Assignment Module 2: Pet Classification\n",
        "\n",
        "The goal of this assignment is to implement a neural network that classifies images of 37 breeds of cats and dogs from the [Oxford-IIIT-Pet dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/). The assignment is divided into two parts: first, you will be asked to implement from scratch your own neural network for image classification; then, you will fine-tune a pretrained network provided by PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1476550",
      "metadata": {
        "id": "b1476550"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The following cells contain the code to download and access the dataset you will be using in this assignment. Note that, although this dataset features each and every image from [Oxford-IIIT-Pet](https://www.robots.ox.ac.uk/~vgg/data/pets/), it uses a different train-val-test split than the original authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d8fb0d2",
      "metadata": {
        "id": "0d8fb0d2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8QtkDSQpXH1B",
      "metadata": {
        "id": "8QtkDSQpXH1B"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/CVLAB-Unibo/ipcv-assignment-2.git\n",
        "!pip install torchview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea1e31f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ea1e31f",
        "outputId": "5e125b49-0307-4144-da36-4121a3e3af7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Check for CUDA availability\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "def fix_random(seed: int) -> None:\n",
        "    \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "    Args:\n",
        "        seed: the seed to use.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "fix_random(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99c9929",
      "metadata": {
        "id": "b99c9929"
      },
      "outputs": [],
      "source": [
        "\n",
        "class OxfordPetDataset(Dataset):\n",
        "    def __init__(self, split: str, transform=None) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.root = Path(\"ipcv-assignment-2\") / \"dataset\"\n",
        "        self.split = split\n",
        "        self.names, self.labels = self._get_names_and_labels()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
        "        img_path = self.root / \"images\" / f\"{self.names[idx]}.jpg\"\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def get_num_classes(self) -> int:\n",
        "        return max(self.labels) + 1\n",
        "\n",
        "    def _get_names_and_labels(self) -> Tuple[List[str], List[int]]:\n",
        "        names = []\n",
        "        labels = []\n",
        "\n",
        "        with open(self.root / \"annotations\" / f\"{self.split}.txt\") as f:\n",
        "            for line in f:\n",
        "                name, label = line.replace(\"\\n\", \"\").split(\" \")\n",
        "                names.append(name),\n",
        "                labels.append(int(label) - 1)\n",
        "\n",
        "        return names, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4e655bd",
      "metadata": {
        "id": "b4e655bd"
      },
      "source": [
        "## Part 1: design your own network\n",
        "\n",
        "Your goal is to implement a convolutional neural network for image classification and train it from scratch on `OxfordPetDataset`. You should consider yourselves satisfied once you obtain a classification accuracy on the test split of ~60%. You are free to achieve this however you want, except for a few rules you must follow:\n",
        "\n",
        "- Compile this notebook by displaying the results obtained by the best model you found throughout your experimentation; then show how, by removing some of its components, its performance drops. In other words, do an *ablation study* to prove that your design choices have a positive impact on the final result.\n",
        "\n",
        "- Do not instantiate an off-the-self PyTorch network. Instead, construct your network as a composition of existing PyTorch layers. In more concrete terms, you can use e.g. `torch.nn.Linear`, but you cannot use e.g. `torchvision.models.alexnet`.\n",
        "\n",
        "- Show your results and ablations with plots, tables, images, etc. — the clearer, the better.\n",
        "\n",
        "Don't be too concerned with your model performance: the ~60% is just to give you an idea of when to stop. Keep in mind that a thoroughly justified model with lower accuracy will be rewarded more points than a poorly experimentally validated model with higher accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a25ddb4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a25ddb4",
        "outputId": "263ba953-245d-457f-91a8-57866f8c1779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 37\n",
            "Training samples: 115\n",
            "Validation samples: 1834\n",
            "Test samples: 46\n",
            "torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# ImageNet mean and std for normalization\n",
        "IMG_SIZE = (224, 224) # A common size for image classification tasks\n",
        "MEAN = [0.485, 0.456, 0.406]\n",
        "STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.TrivialAugmentWide(),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(MEAN, STD)\n",
        "])\n",
        "\n",
        "# Create Dataset instances\n",
        "train_dataset = OxfordPetDataset(split=\"train\", transform=train_transform)\n",
        "val_dataset = OxfordPetDataset(split=\"val\", transform=val_test_transform)\n",
        "test_dataset = OxfordPetDataset(split=\"test\", transform=val_test_transform)\n",
        "\n",
        "# Create DataLoader instances\n",
        "BATCH_SIZE = 256 # You can tune this hyperparameter\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "# Get number of classes\n",
        "NUM_CLASSES = train_dataset.get_num_classes()\n",
        "INPUT_DIM = len(train_dataset[0][0])\n",
        "print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "print(train_dataset[0][0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "000de0e4",
      "metadata": {
        "id": "000de0e4"
      },
      "source": [
        "We choose to implement from scratch the Depthwise Separable convolution used in MobileNet architectures. It performs convolution in two steps:\n",
        "1. Depthwise convolution: applies a separate 3×3 filter to each input channel independently (``groups = in_channels``)\n",
        "2. Pointwise convolution: applies a 1×1 convolution across all channels to combine the depthwise outputs.\n",
        "\n",
        "\n",
        "We decided to use Depthwise convolution to reduce parameters from $k^2 C_{in} C_{out}$ to  $k^2 C_{in}+ C_{in} C_{out}$ while still mantaining accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72085aec",
      "metadata": {
        "id": "72085aec"
      },
      "outputs": [],
      "source": [
        "class DepthWiseSeperable(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels , out_channels , stride):\n",
        "        \"\"\"\n",
        "        DepthWiseSeperable block of MobileNet.\n",
        "\n",
        "        Args:\n",
        "          in_channels (int) : number of input channels\n",
        "          out_channels (int) : number of output channels\n",
        "          stride (int) : stride used for depthwise convolution\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        super(DepthWiseSeperable,self).__init__()\n",
        "\n",
        "        self.depthwise = nn.Conv2d(in_channels = in_channels , out_channels = in_channels , stride = stride , padding = 1, kernel_size = 3 , groups=in_channels , bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "\n",
        "        self.pointwise = nn.Conv2d(in_channels = in_channels , out_channels = out_channels , stride = 1 , padding = 0, kernel_size = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.depthwise(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.pointwise(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "112cbb20",
      "metadata": {
        "id": "112cbb20"
      },
      "outputs": [],
      "source": [
        "class MobileNetV1(nn.Module):\n",
        "\n",
        "    def __init__(self, num_depthwise_512, dropout_percent = 0.2, reduction_coefficient = 1, kernel_size = 3):\n",
        "        super(MobileNetV1, self).__init__()\n",
        "        rc = reduction_coefficient\n",
        "        padding = (kernel_size - 1) // 2\n",
        "\n",
        "        # Stem layer\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=kernel_size, stride=2, padding=padding, bias = False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Modular number of 512→512 depthwise separable blocks\n",
        "        depthwise_512_channels = [\n",
        "            DepthWiseSeperable(int(rc * 512), int(rc * 512), 1) for i in range(num_depthwise_512)\n",
        "        ]\n",
        "\n",
        "        # Depthwise separable convolutions\n",
        "        self.features = nn.Sequential(\n",
        "            self.features,\n",
        "            DepthWiseSeperable(32, int(rc * 64), 1),\n",
        "            DepthWiseSeperable(int(rc * 64), int(rc * 128), 2),\n",
        "            DepthWiseSeperable(int(rc * 128), int(rc * 128), 1),\n",
        "            DepthWiseSeperable(int(rc * 128), int(rc * 256), 2),\n",
        "            DepthWiseSeperable(int(rc * 256), int(rc * 256), 1),\n",
        "            DepthWiseSeperable(int(rc * 256), int(rc * 512), 2),\n",
        "\n",
        "            *depthwise_512_channels,\n",
        "\n",
        "            DepthWiseSeperable(int(rc * 512), int(rc * 1024), 2),\n",
        "            DepthWiseSeperable(int(rc * 1024), int(rc * 1024), 1)\n",
        "        )\n",
        "\n",
        "        # Average pooling and classifier\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout_percent),\n",
        "            nn.Linear(int(rc * 1024), 37)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e4a6876",
      "metadata": {
        "id": "1e4a6876"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model: nn.Module,\n",
        "                dataloader: DataLoader,\n",
        "                criterion: nn.Module,\n",
        "                optimizer: optim.Optimizer,\n",
        "                device: torch.device,\n",
        "                scheduler: Optional[lr_scheduler.LRScheduler] = None) -> Tuple[float, float]:\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct_predictions += torch.sum(preds == labels.data)\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = epoch_loss / total_samples\n",
        "    avg_acc = correct_predictions.double() / total_samples\n",
        "    return avg_loss, avg_acc.item()\n",
        "\n",
        "def evaluate_model(model: nn.Module,\n",
        "                   dataloader: DataLoader,\n",
        "                   criterion: nn.Module,\n",
        "                   device: torch.device) -> Tuple[float, float]:\n",
        "    model.eval()\n",
        "    epoch_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            epoch_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_predictions += torch.sum(preds == labels.data)\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    avg_loss = epoch_loss / total_samples\n",
        "    avg_acc = correct_predictions.double() / total_samples\n",
        "    return avg_loss, avg_acc.item()\n",
        "\n",
        "def plot_history(history: Dict[str, List[float]]):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
        "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c250bd",
      "metadata": {
        "id": "94c250bd"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 180\n",
        "\n",
        "def run_experiment(config: Dict, model = None):\n",
        "    print(\"=\"*60 + f\"\\nStart running the model: {config['experiment_name']}\\n\" + \"=\"*60)\n",
        "    fix_random(42)\n",
        "\n",
        "    model = config[\"model\"]\n",
        "\n",
        "    # Setup of early stopping, LR schedule and weight decay\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.get(\"lr\", 1e-3), weight_decay=config['weight_decay'])\n",
        "    if config['use_scheduler']:\n",
        "        warmup_scheduler = lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1.0, total_iters=5)\n",
        "        main_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=15)\n",
        "\n",
        "    # Training Loop\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "    best_val_acc = 0.0\n",
        "    pbar = tqdm(range(EPOCHS), desc=f\"Training {config['experiment_name']}\")\n",
        "    for epoch in pbar:\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, DEVICE)\n",
        "        history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n",
        "        if config['use_scheduler']:\n",
        "            if epoch < 5: warmup_scheduler.step()\n",
        "            else: main_scheduler.step(val_acc)\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f\"{config['experiment_name']}.pt\")\n",
        "            #print(f\"Saved new best model, val acc: {val_acc}\")\n",
        "        pbar.set_postfix({\"Val Acc\": f\"{val_acc:.4f}\", \"Train Acc\": f\"{train_acc:.4f}\"})\n",
        "\n",
        "    # Final test and save result\n",
        "    sd = torch.load(f\"{config['experiment_name']}.pt\")\n",
        "    model.load_state_dict(sd)\n",
        "    _, test_acc = evaluate_model(model, test_loader, criterion, DEVICE)\n",
        "    print(f\"Model '{config['experiment_name']}' completed. Test Accuracy: {test_acc:.4f}\\n\")\n",
        "\n",
        "    result = config.copy()\n",
        "    result.update({'test_accuracy': test_acc, 'best_val_accuracy': best_val_acc, 'history': history})\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-Wipikz4gUsG",
      "metadata": {
        "id": "-Wipikz4gUsG"
      },
      "source": [
        "## Ablation study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c438dc70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "c438dc70",
        "outputId": "ded4b823-2973-4344-90d0-5d5bf15df1aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Start running the model: mobilenetv1_small\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training mobilenetv1_small:  20%|██        | 2/10 [02:33<10:09, 76.16s/it, Val Acc=0.0273, Train Acc=0.0174]"
          ]
        }
      ],
      "source": [
        "mobile_configs = [\n",
        "# Ablation on the depthwise layers in the network\n",
        "{\n",
        "    'experiment_name': 'mobilenetv1_small',\n",
        "    'lr': 1e-3,\n",
        "    'weight_decay': 1e-4,\n",
        "    'use_scheduler': True,\n",
        "    \"model\": MobileNetV1(num_depthwise_512=2, dropout_percent=0.2, reduction_coefficient=1).to(DEVICE)\n",
        "}\n",
        "]\n",
        "\n",
        "for conf in mobile_configs:\n",
        "    result= run_experiment(conf)\n",
        "    df = pd.DataFrame(result).to_csv(f\"./{result['experiment_name']}.csv\")\n",
        "    plot_history(result['history'])\n",
        "    print(f\"\\nFinal Results for {result['experiment_name']}:\")\n",
        "    print(f\"Best Validation Accuracy: {result['best_val_accuracy']:.4f}\")\n",
        "    print(f\"Test Accuracy: {result['test_accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5911028b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save the model after the training loop is complete\n",
        "for conf in mobile_configs:\n",
        "    model_name = conf['experiment_name']\n",
        "    model_path = f\"{model_name}.pt\"  # Assuming the model is saved in the current directory\n",
        "    drive_path = f\"/content/drive/MyDrive/model_weights/{model_name}.pt\"\n",
        "    try:\n",
        "        # Check if the model file exists before attempting to copy\n",
        "        if os.path.exists(model_path):\n",
        "            !cp \"{model_path}\" \"{drive_path}\"\n",
        "            print(f\"Model '{model_name}' saved to Google Drive at '{drive_path}'\")\n",
        "        else:\n",
        "            print(f\"Model file '{model_path}' not found. Skipping save to Google Drive.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model '{model_name}' to Google Drive: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a59930b0",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
