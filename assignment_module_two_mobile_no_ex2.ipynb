{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41535fd",
   "metadata": {},
   "source": [
    "# Assignment Module 2: Pet Classification\n",
    "\n",
    "The goal of this assignment is to implement a neural network that classifies images of 37 breeds of cats and dogs from the [Oxford-IIIT-Pet dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/). The assignment is divided into two parts: first, you will be asked to implement from scratch your own neural network for image classification; then, you will fine-tune a pretrained network provided by PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1476550",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The following cells contain the code to download and access the dataset you will be using in this assignment. Note that, although this dataset features each and every image from [Oxford-IIIT-Pet](https://www.robots.ox.ac.uk/~vgg/data/pets/), it uses a different train-val-test split than the original authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91101a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ipcv-assignment-2' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/CVLAB-Unibo/ipcv-assignment-2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8fb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchview import draw_graph\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea1e31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA availability\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99c9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OxfordPetDataset(Dataset):\n",
    "    def __init__(self, split: str, transform=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = Path(\"ipcv-assignment-2\") / \"dataset\"\n",
    "        self.split = split\n",
    "        self.names, self.labels = self._get_names_and_labels()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
    "        img_path = self.root / \"images\" / f\"{self.names[idx]}.jpg\"\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "    \n",
    "    def get_num_classes(self) -> int:\n",
    "        return max(self.labels) + 1\n",
    "\n",
    "    def _get_names_and_labels(self) -> Tuple[List[str], List[int]]:\n",
    "        names = []\n",
    "        labels = []\n",
    "\n",
    "        with open(self.root / \"annotations\" / f\"{self.split}.txt\") as f:\n",
    "            for line in f:\n",
    "                name, label = line.replace(\"\\n\", \"\").split(\" \")\n",
    "                names.append(name), \n",
    "                labels.append(int(label) - 1)\n",
    "\n",
    "        return names, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e655bd",
   "metadata": {},
   "source": [
    "## Part 1: design your own network\n",
    "\n",
    "Your goal is to implement a convolutional neural network for image classification and train it from scratch on `OxfordPetDataset`. You should consider yourselves satisfied once you obtain a classification accuracy on the test split of ~60%. You are free to achieve this however you want, except for a few rules you must follow:\n",
    "\n",
    "- Compile this notebook by displaying the results obtained by the best model you found throughout your experimentation; then show how, by removing some of its components, its performance drops. In other words, do an *ablation study* to prove that your design choices have a positive impact on the final result.\n",
    "\n",
    "- Do not instantiate an off-the-self PyTorch network. Instead, construct your network as a composition of existing PyTorch layers. In more concrete terms, you can use e.g. `torch.nn.Linear`, but you cannot use e.g. `torchvision.models.alexnet`.\n",
    "\n",
    "- Show your results and ablations with plots, tables, images, etc. — the clearer, the better.\n",
    "\n",
    "Don't be too concerned with your model performance: the ~60% is just to give you an idea of when to stop. Keep in mind that a thoroughly justified model with lower accuracy will be rewarded more points than a poorly experimentally validated model with higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a25ddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 37\n",
      "Training samples: 3669\n",
      "Validation samples: 1834\n",
      "Test samples: 1846\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# ImageNet mean and std for normalization\n",
    "IMG_SIZE = (224, 224) # A common size for image classification tasks\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD)\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN, STD)\n",
    "])\n",
    "\n",
    "# Create Dataset instances\n",
    "train_dataset = OxfordPetDataset(split=\"train\", transform=train_transform)\n",
    "val_dataset = OxfordPetDataset(split=\"val\", transform=val_test_transform)\n",
    "test_dataset = OxfordPetDataset(split=\"test\", transform=val_test_transform)\n",
    "\n",
    "# Create DataLoader instances\n",
    "BATCH_SIZE = 128 # You can tune this hyperparameter\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Get number of classes\n",
    "NUM_CLASSES = train_dataset.get_num_classes()\n",
    "INPUT_DIM = len(train_dataset[0][0])\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000de0e4",
   "metadata": {},
   "source": [
    "We use Depthwise convolution to reduce parameters from $k^2 C_{in} C_{out}$ to  $k^2 C_{in}+ C_{in} C_{out}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72085aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: self_DepthWiseSeperable Pages: 1 -->\n",
       "<svg width=\"226pt\" height=\"576pt\"\n",
       " viewBox=\"0.00 0.00 226.00 576.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 572)\">\n",
       "<title>self_DepthWiseSeperable</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-572 222,-572 222,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"189,-568 29,-568 29,-536 189,-536 189,-568\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"29,-536 29,-568 99,-568 99,-536 29,-536\"/>\n",
       "<text text-anchor=\"start\" x=\"34\" y=\"-555\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"45.5\" y=\"-544\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99,-536 99,-568 189,-568 189,-536 99,-536\"/>\n",
       "<text text-anchor=\"start\" x=\"104\" y=\"-549.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 224, 224)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"203,-500 15,-500 15,-458 203,-458 203,-500\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"15,-458 15,-500 62,-500 62,-458 15,-458\"/>\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-482\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-471\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"62,-479 62,-500 110,-500 110,-479 62,-479\"/>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-479 110,-500 203,-500 203,-479 110,-479\"/>\n",
       "<text text-anchor=\"start\" x=\"115\" y=\"-487\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 224, 224) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"62,-458 62,-479 110,-479 110,-458 62,-458\"/>\n",
       "<text text-anchor=\"start\" x=\"67\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-458 110,-479 203,-479 203,-458 110,-458\"/>\n",
       "<text text-anchor=\"start\" x=\"115\" y=\"-466\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-535.94C109,-528.45 109,-519.12 109,-510.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-510.16 109,-500.16 105.5,-510.16 112.5,-510.16\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"218,-422 0,-422 0,-380 218,-380 218,-422\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-380 0,-422 77,-422 77,-380 0,-380\"/>\n",
       "<text text-anchor=\"start\" x=\"5\" y=\"-404\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-393\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"77,-401 77,-422 125,-422 125,-401 77,-401\"/>\n",
       "<text text-anchor=\"start\" x=\"87\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125,-401 125,-422 218,-422 218,-401 125,-401\"/>\n",
       "<text text-anchor=\"start\" x=\"130\" y=\"-409\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"77,-380 77,-401 125,-401 125,-380 77,-380\"/>\n",
       "<text text-anchor=\"start\" x=\"82\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125,-380 125,-401 218,-401 218,-380 125,-380\"/>\n",
       "<text text-anchor=\"start\" x=\"130\" y=\"-388\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-457.63C109,-449.82 109,-440.73 109,-432.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-432.16 109,-422.16 105.5,-432.16 112.5,-432.16\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"203,-344 15,-344 15,-302 203,-302 203,-344\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"15,-302 15,-344 62,-344 62,-302 15,-302\"/>\n",
       "<text text-anchor=\"start\" x=\"25.5\" y=\"-326\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-315\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"62,-323 62,-344 110,-344 110,-323 62,-323\"/>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-323 110,-344 203,-344 203,-323 110,-323\"/>\n",
       "<text text-anchor=\"start\" x=\"115\" y=\"-331\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"62,-302 62,-323 110,-323 110,-302 62,-302\"/>\n",
       "<text text-anchor=\"start\" x=\"67\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-302 110,-323 203,-323 203,-302 110,-302\"/>\n",
       "<text text-anchor=\"start\" x=\"115\" y=\"-310\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-379.63C109,-371.82 109,-362.73 109,-354.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-354.16 109,-344.16 105.5,-354.16 112.5,-354.16\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"203,-266 15,-266 15,-224 203,-224 203,-266\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"15,-224 15,-266 62,-266 62,-224 15,-224\"/>\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-248\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-237\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"62,-245 62,-266 110,-266 110,-245 62,-245\"/>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-245 110,-266 203,-266 203,-245 110,-245\"/>\n",
       "<text text-anchor=\"start\" x=\"115\" y=\"-253\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 32, 112, 112) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"62,-224 62,-245 110,-245 110,-224 62,-224\"/>\n",
       "<text text-anchor=\"start\" x=\"67\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-224 110,-245 203,-245 203,-224 110,-224\"/>\n",
       "<text text-anchor=\"start\" x=\"115\" y=\"-232\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 112, 112) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-301.63C109,-293.82 109,-284.73 109,-276.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-276.16 109,-266.16 105.5,-276.16 112.5,-276.16\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"218,-188 0,-188 0,-146 218,-146 218,-188\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-146 0,-188 77,-188 77,-146 0,-146\"/>\n",
       "<text text-anchor=\"start\" x=\"5\" y=\"-170\" font-family=\"Linux libertine\" font-size=\"10.00\">BatchNorm2d</text>\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-159\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"77,-167 77,-188 125,-188 125,-167 77,-167\"/>\n",
       "<text text-anchor=\"start\" x=\"87\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125,-167 125,-188 218,-188 218,-167 125,-167\"/>\n",
       "<text text-anchor=\"start\" x=\"130\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 112, 112) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"77,-146 77,-167 125,-167 125,-146 77,-146\"/>\n",
       "<text text-anchor=\"start\" x=\"82\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125,-146 125,-167 218,-167 218,-146 125,-146\"/>\n",
       "<text text-anchor=\"start\" x=\"130\" y=\"-154\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 112, 112) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-223.63C109,-215.82 109,-206.73 109,-198.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-198.16 109,-188.16 105.5,-198.16 112.5,-198.16\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"transparent\" points=\"203,-110 15,-110 15,-68 203,-68 203,-110\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"15,-68 15,-110 62,-110 62,-68 15,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"25.5\" y=\"-92\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-81\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"62,-89 62,-110 110,-110 110,-89 62,-89\"/>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-89 110,-110 203,-110 203,-89 110,-89\"/>\n",
       "<text text-anchor=\"start\" x=\"115\" y=\"-97\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 112, 112) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"62,-68 62,-89 110,-89 110,-68 62,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"67\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"110,-68 110,-89 203,-89 203,-68 110,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"115\" y=\"-76\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 112, 112) </text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-145.63C109,-137.82 109,-128.73 109,-120.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-120.16 109,-110.16 105.5,-120.16 112.5,-120.16\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"transparent\" points=\"192.5,-32 25.5,-32 25.5,0 192.5,0 192.5,-32\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"26,0 26,-32 103,-32 103,0 26,0\"/>\n",
       "<text text-anchor=\"start\" x=\"31\" y=\"-19\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"46\" y=\"-8\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103,0 103,-32 193,-32 193,0 103,0\"/>\n",
       "<text text-anchor=\"start\" x=\"108\" y=\"-13.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 64, 112, 112)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-67.84C109,-59.89 109,-50.66 109,-42.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-42.24 109,-32.24 105.5,-42.24 112.5,-42.24\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7160d6dc8460>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DepthWiseSeperable(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels , out_channels , stride ):\n",
    "        \"\"\"\n",
    "        DepthWiseSeperable block of MobileNet which performs the following operations:\n",
    "        (a) depthwise convolution by applying a separate filter for each channel\n",
    "        (b) pointwise convolutions are applied which combine the filtered result by implementing 1 × 1 convolution\n",
    "        \n",
    "            Note:\n",
    "                1. groups = in_channels used for depthwise convolution\n",
    "                2. in_channels and out_channels are same for depthwise convolution\n",
    "                3. bias = False due to the usage of BatchNorm \n",
    "                4. To generate same height and width of output feature map as the input feature map, following should be padding for\n",
    "                    * 1x1 conv : p=0\n",
    "                    * 3x3 conv : p=1\n",
    "                    * 5x5 conv : p=2\n",
    "\n",
    "\n",
    "        Args:\n",
    "          in_channels (int) : number of input channels\n",
    "          out_channels (int) : number of output channels \n",
    "          stride (int) : stride used for depthwise convolution\n",
    "\n",
    "        Attributes:\n",
    "            Depthwise seperable convolutional block\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(DepthWiseSeperable,self).__init__()\n",
    "        \n",
    "        # groups used here\n",
    "        self.depthwise = nn.Conv2d(in_channels = in_channels , out_channels = in_channels , stride = stride , padding = 1, kernel_size = 3 , groups=in_channels , bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "        self.pointwise = nn.Conv2d(in_channels = in_channels , out_channels = out_channels , stride = 1 , padding = 0, kernel_size = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def test_DepthWiseSeperable():\n",
    "    x = torch.randn(1,32,224,224)\n",
    "    model = DepthWiseSeperable(32,64,2)\n",
    "    print(model(x).shape)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = test_DepthWiseSeperable()\n",
    "architecture = 'DepthWiseSeperable'\n",
    "model_graph = draw_graph(model, input_size=(1,32,224,224), graph_dir ='TB' , roll=True, expand_nested=True, graph_name=f'self_{architecture}',save_graph=True,filename=f'self_{architecture}')\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112cbb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "class MobileNetV1(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        \n",
    "        super(MobileNetV1, self).__init__()\n",
    "\n",
    "        # Initial convolution layer\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Depthwise separable convolutions\n",
    "        self.features = nn.Sequential(\n",
    "            self.features,\n",
    "            DepthWiseSeperable(32, 64, 1),\n",
    "            DepthWiseSeperable(64, 128, 2),\n",
    "            DepthWiseSeperable(128, 128, 1),\n",
    "            DepthWiseSeperable(128, 256, 2),\n",
    "            DepthWiseSeperable(256, 256, 1),\n",
    "            DepthWiseSeperable(256, 512, 2),\n",
    "            \n",
    "            DepthWiseSeperable(512, 512, 1),\n",
    "            DepthWiseSeperable(512, 512, 1),\n",
    "            DepthWiseSeperable(512, 512, 1),\n",
    "            DepthWiseSeperable(512, 512, 1),\n",
    "            DepthWiseSeperable(512, 512, 1),\n",
    "\n",
    "            DepthWiseSeperable(512, 1024, 2),\n",
    "            DepthWiseSeperable(1024, 1024, 1)\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Average pooling and classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1280, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create an instance of MobileNetV1\n",
    "model = MobileNetV1()\n",
    "# print(model)\n",
    "\n",
    "\n",
    "def test_Mobilenet():\n",
    "    x = torch.randn(1,3,224,224)\n",
    "    model = MobileNetV1()\n",
    "    print(model(x).shape)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = test_Mobilenet()\n",
    "architecture = 'mobilenetv1'\n",
    "model_graph = draw_graph(model, input_size=(1,3,224,224), graph_dir ='TB' , roll=True, expand_nested=True, graph_name=f'self_{architecture}',save_graph=True,filename=f'self_{architecture}')\n",
    "# model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eaab04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "              ReLU-2         [-1, 32, 112, 112]               0\n",
      "       BatchNorm2d-3         [-1, 32, 112, 112]              64\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "              ReLU-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 64, 112, 112]           2,048\n",
      "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
      "              ReLU-9         [-1, 64, 112, 112]               0\n",
      "DepthWiseSeperable-10         [-1, 64, 112, 112]               0\n",
      "           Conv2d-11           [-1, 64, 56, 56]             576\n",
      "      BatchNorm2d-12           [-1, 64, 56, 56]             128\n",
      "             ReLU-13           [-1, 64, 56, 56]               0\n",
      "           Conv2d-14          [-1, 128, 56, 56]           8,192\n",
      "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
      "             ReLU-16          [-1, 128, 56, 56]               0\n",
      "DepthWiseSeperable-17          [-1, 128, 56, 56]               0\n",
      "           Conv2d-18          [-1, 128, 56, 56]           1,152\n",
      "      BatchNorm2d-19          [-1, 128, 56, 56]             256\n",
      "             ReLU-20          [-1, 128, 56, 56]               0\n",
      "           Conv2d-21          [-1, 128, 56, 56]          16,384\n",
      "      BatchNorm2d-22          [-1, 128, 56, 56]             256\n",
      "             ReLU-23          [-1, 128, 56, 56]               0\n",
      "DepthWiseSeperable-24          [-1, 128, 56, 56]               0\n",
      "           Conv2d-25          [-1, 128, 28, 28]           1,152\n",
      "      BatchNorm2d-26          [-1, 128, 28, 28]             256\n",
      "             ReLU-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 256, 28, 28]          32,768\n",
      "      BatchNorm2d-29          [-1, 256, 28, 28]             512\n",
      "             ReLU-30          [-1, 256, 28, 28]               0\n",
      "DepthWiseSeperable-31          [-1, 256, 28, 28]               0\n",
      "           Conv2d-32          [-1, 256, 28, 28]           2,304\n",
      "      BatchNorm2d-33          [-1, 256, 28, 28]             512\n",
      "             ReLU-34          [-1, 256, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 28, 28]          65,536\n",
      "      BatchNorm2d-36          [-1, 256, 28, 28]             512\n",
      "             ReLU-37          [-1, 256, 28, 28]               0\n",
      "DepthWiseSeperable-38          [-1, 256, 28, 28]               0\n",
      "           Conv2d-39          [-1, 256, 14, 14]           2,304\n",
      "      BatchNorm2d-40          [-1, 256, 14, 14]             512\n",
      "             ReLU-41          [-1, 256, 14, 14]               0\n",
      "           Conv2d-42          [-1, 512, 14, 14]         131,072\n",
      "      BatchNorm2d-43          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-44          [-1, 512, 14, 14]               0\n",
      "DepthWiseSeperable-45          [-1, 512, 14, 14]               0\n",
      "           Conv2d-46          [-1, 512, 14, 14]           4,608\n",
      "      BatchNorm2d-47          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-48          [-1, 512, 14, 14]               0\n",
      "           Conv2d-49          [-1, 512, 14, 14]         262,144\n",
      "      BatchNorm2d-50          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-51          [-1, 512, 14, 14]               0\n",
      "DepthWiseSeperable-52          [-1, 512, 14, 14]               0\n",
      "           Conv2d-53          [-1, 512, 14, 14]           4,608\n",
      "      BatchNorm2d-54          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-55          [-1, 512, 14, 14]               0\n",
      "           Conv2d-56          [-1, 512, 14, 14]         262,144\n",
      "      BatchNorm2d-57          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-58          [-1, 512, 14, 14]               0\n",
      "DepthWiseSeperable-59          [-1, 512, 14, 14]               0\n",
      "           Conv2d-60          [-1, 512, 14, 14]           4,608\n",
      "      BatchNorm2d-61          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-62          [-1, 512, 14, 14]               0\n",
      "           Conv2d-63          [-1, 512, 14, 14]         262,144\n",
      "      BatchNorm2d-64          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-65          [-1, 512, 14, 14]               0\n",
      "DepthWiseSeperable-66          [-1, 512, 14, 14]               0\n",
      "           Conv2d-67          [-1, 512, 14, 14]           4,608\n",
      "      BatchNorm2d-68          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-69          [-1, 512, 14, 14]               0\n",
      "           Conv2d-70          [-1, 512, 14, 14]         262,144\n",
      "      BatchNorm2d-71          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-72          [-1, 512, 14, 14]               0\n",
      "DepthWiseSeperable-73          [-1, 512, 14, 14]               0\n",
      "           Conv2d-74          [-1, 512, 14, 14]           4,608\n",
      "      BatchNorm2d-75          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-76          [-1, 512, 14, 14]               0\n",
      "           Conv2d-77          [-1, 512, 14, 14]         262,144\n",
      "      BatchNorm2d-78          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-79          [-1, 512, 14, 14]               0\n",
      "DepthWiseSeperable-80          [-1, 512, 14, 14]               0\n",
      "           Conv2d-81            [-1, 512, 7, 7]           4,608\n",
      "      BatchNorm2d-82            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-83            [-1, 512, 7, 7]               0\n",
      "           Conv2d-84           [-1, 1024, 7, 7]         524,288\n",
      "      BatchNorm2d-85           [-1, 1024, 7, 7]           2,048\n",
      "             ReLU-86           [-1, 1024, 7, 7]               0\n",
      "DepthWiseSeperable-87           [-1, 1024, 7, 7]               0\n",
      "           Conv2d-88           [-1, 1024, 7, 7]           9,216\n",
      "      BatchNorm2d-89           [-1, 1024, 7, 7]           2,048\n",
      "             ReLU-90           [-1, 1024, 7, 7]               0\n",
      "           Conv2d-91           [-1, 1024, 7, 7]       1,048,576\n",
      "      BatchNorm2d-92           [-1, 1024, 7, 7]           2,048\n",
      "             ReLU-93           [-1, 1024, 7, 7]               0\n",
      "DepthWiseSeperable-94           [-1, 1024, 7, 7]               0\n",
      "AdaptiveAvgPool2d-95           [-1, 1024, 1, 1]               0\n",
      "           Linear-96                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 4,231,976\n",
      "Trainable params: 4,231,976\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 136.11\n",
      "Params size (MB): 16.14\n",
      "Estimated Total Size (MB): 152.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e4a6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model: nn.Module,\n",
    "                dataloader: DataLoader,\n",
    "                criterion: nn.Module,\n",
    "                optimizer: optim.Optimizer,\n",
    "                device: torch.device,\n",
    "                scheduler: Optional[lr_scheduler.LRScheduler] = None) -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None: \n",
    "            scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_predictions += torch.sum(preds == labels.data)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = epoch_loss / total_samples\n",
    "    avg_acc = correct_predictions.double() / total_samples\n",
    "    return avg_loss, avg_acc.item()\n",
    "\n",
    "def evaluate_model(model: nn.Module,\n",
    "                   dataloader: DataLoader,\n",
    "                   criterion: nn.Module,\n",
    "                   device: torch.device) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_predictions += torch.sum(preds == labels.data)\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = epoch_loss / total_samples\n",
    "    avg_acc = correct_predictions.double() / total_samples\n",
    "    return avg_loss, avg_acc.item()\n",
    "\n",
    "def plot_history(history: Dict[str, List[float]]):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c250bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "def run_experiment(config: Dict, model = None):\n",
    "    print(\"=\"*60 + f\"\\nStart running the model: {config['experiment_name']}\\n\" + \"=\"*60)\n",
    "    fix_random(42)\n",
    "\n",
    "    if model is None:\n",
    "        model = MobileNetV1(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "    # Setup of Early stopping, LR schedule and weight decay\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.get(\"lr\", 1e-3), weight_decay=config['weight_decay'])\n",
    "    if config['use_scheduler']:\n",
    "        warmup_scheduler = lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1.0, total_iters=5)\n",
    "        main_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=15)\n",
    "\n",
    "    # Training Loop\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_acc = 0.0\n",
    "    pbar = tqdm(range(EPOCHS), desc=f\"Training {config['experiment_name']}\")\n",
    "    for epoch in pbar:\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, DEVICE)\n",
    "        history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n",
    "        if config['use_scheduler']:\n",
    "            if epoch < 5: warmup_scheduler.step()\n",
    "            else: main_scheduler.step(val_acc)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f\"{config['experiment_name']}.pt\")\n",
    "            #print(f\"Saved new best model, val acc: {val_acc}\")\n",
    "        pbar.set_postfix({\"Val Acc\": f\"{val_acc:.4f}\", \"Train Acc\": f\"{train_acc:.4f}\"})\n",
    "\n",
    "    # Final test and save result\n",
    "    sd = torch.load(f\"{config['experiment_name']}.pt\")\n",
    "    model.load_state_dict(sd)\n",
    "    _, test_acc = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "    print(f\"Model '{config['experiment_name']}' completed. Test Accuracy: {test_acc:.4f}\\n\")\n",
    "\n",
    "    result = config.copy()\n",
    "    result.update({'test_accuracy': test_acc, 'best_val_accuracy': best_val_acc, 'history': history})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c438dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Start running the model: mobilenetv1_baseline\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training mobilenetv1_baseline:   0%|          | 0/200 [00:26<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m mobile_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobilenetv1_baseline\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1e-3\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_scheduler\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m result\u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmobile_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m plot_history(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(config, model)\u001b[0m\n\u001b[1;32m     21\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(EPOCHS), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m---> 23\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate_model(model, val_loader, criterion, DEVICE)\n\u001b[1;32m     25\u001b[0m     history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss); history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[1;32m     21\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 23\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     24\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m correct_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mobile_config = {\n",
    "    'experiment_name': 'mobilenetv1_baseline',\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 1e-4,\n",
    "    'use_scheduler': True,\n",
    "}\n",
    "\n",
    "result= run_experiment(mobile_config)\n",
    "plot_history(result['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79401a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nFinal Results for {result['experiment_name']}:\")\n",
    "print(f\"Best Validation Accuracy: {result['best_val_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy: {result['test_accuracy']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipcvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
